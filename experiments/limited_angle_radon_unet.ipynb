{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0efad49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import scipy.io\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from tqdm import tqdm\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv_op = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=\"same\"),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=\"same\"),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_op(x)\n",
    "\n",
    "\n",
    "class DownSample(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "        self.pool = nn.AvgPool2d(kernel_size=(2,2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        down = self.conv(x)\n",
    "        p = self.pool(down)\n",
    "        return down, p\n",
    "\n",
    "\n",
    "class UpSample(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.up   = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        x = torch.cat([x1, x2], 1)\n",
    "        return self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c5b1f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "class u_net(nn.Module):\n",
    "    def __init__(self, in_channels, feat):\n",
    "        super().__init__()\n",
    "        self.down_convolution_1 = DownSample(in_channels,   feat)\n",
    "        self.down_convolution_2 = DownSample(    feat,  2 * feat)\n",
    "        self.down_convolution_3 = DownSample(2 * feat,  4 * feat)\n",
    "        self.down_convolution_4 = DownSample(4 * feat,  8 * feat)\n",
    "\n",
    "        self.bottle_neck        = DoubleConv(8 * feat, 16 * feat)\n",
    "\n",
    "        self.up_convolution_1 = UpSample(16 * feat + 8 * feat,  8 * feat)\n",
    "        self.up_convolution_2 = UpSample(8  * feat + 4 * feat,  4 * feat)\n",
    "        self.up_convolution_3 = UpSample(4  * feat + 2 * feat,  2 * feat)\n",
    "        self.up_convolution_4 = UpSample(2  * feat +     feat,      feat)\n",
    "\n",
    "        # Sigmoid to convert the numerics\n",
    "        self.out = nn.Conv2d(in_channels=feat, out_channels=1, kernel_size=1)\n",
    "        self.sig =nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        down_1, p1 = self.down_convolution_1(x)\n",
    "        down_2, p2 = self.down_convolution_2(p1)\n",
    "        down_3, p3 = self.down_convolution_3(p2)\n",
    "        down_4, p4 = self.down_convolution_4(p3)\n",
    "\n",
    "        b = self.bottle_neck(p4)\n",
    "\n",
    "        up_1 = self.up_convolution_1(b, down_4)\n",
    "        up_2 = self.up_convolution_2(up_1, down_3)\n",
    "        up_3 = self.up_convolution_3(up_2, down_2)\n",
    "        up_4 = self.up_convolution_4(up_3, down_1)\n",
    "\n",
    "        out = self.out(up_4)\n",
    "       \n",
    "        return self.sig(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b61d6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder containing .mat files\n",
    "\n",
    "ANGLE = \"120\" # \"120\", \"100\", \"80\"\n",
    "\n",
    "x_folder_path = 'train/XImages'+ANGLE\n",
    "y_folder_path = 'train/YImages'\n",
    "\n",
    "# List all .mat files in the folder\n",
    "x_mat_files = sorted([f for f in os.listdir(x_folder_path) if f.endswith('.mat')])\n",
    "y_mat_files = sorted([f for f in os.listdir(y_folder_path) if f.endswith('.mat')])\n",
    "\n",
    "x_train_list = []  # list of artifact images with missing angle (180 - ANGLE)\n",
    "y_train_list = []  # list of true images\n",
    "sample_size = 10000\n",
    "for i in range(sample_size):\n",
    "    x_mat = scipy.io.loadmat(os.path.join(x_folder_path, x_mat_files[i]))\n",
    "#     print(x_mat)\n",
    "    x_train = x_mat['P']\n",
    "    x_train_list.append(x_train)\n",
    "    \n",
    "    y_mat = scipy.io.loadmat(os.path.join(y_folder_path, y_mat_files[i]))\n",
    "    y_train = y_mat['im_reduced']\n",
    "    y_train_list.append(y_train)\n",
    "\n",
    "x_train_full = np.array(x_train_list)\n",
    "y_train_full = np.array(y_train_list)\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "plt.imshow(x_train_full[1],cmap='gray') \n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "plt.imshow(y_train_full[1],cmap='gray')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6afd1b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training data\n",
    "\n",
    "xdata = x_train_full[:5000]\n",
    "ydata = y_train_full[:5000]\n",
    "\n",
    "test_xdata = x_train_full[5000::]\n",
    "test_ydata = y_train_full[5000::]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5930e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "\n",
    "class CT_Dataset(Dataset):\n",
    "    def __init__(self, xdata, ydata):\n",
    "        self.xdata = torch.tensor(xdata).unsqueeze(dim=1)\n",
    "        self.ydata = torch.tensor(ydata).unsqueeze(dim=1)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x_img = self.xdata[index]\n",
    "        y_img = self.ydata[index]\n",
    "\n",
    "        return x_img, y_img\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.xdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760d5dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 50\n",
    "\n",
    "train_dataset = CT_Dataset(xdata, ydata)\n",
    "test_dataset = CT_Dataset(test_xdata, test_ydata)\n",
    "\n",
    "generator = torch.Generator().manual_seed(42)\n",
    "\n",
    "train_dataset, val_dataset = random_split(train_dataset, [0.8, 0.2], generator=generator)\n",
    "\n",
    "train_dataloader = DataLoader(dataset=train_dataset,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=True)\n",
    "val_dataloader = DataLoader(dataset=val_dataset,\n",
    "                            batch_size=BATCH_SIZE,\n",
    "                            shuffle=True)\n",
    "\n",
    "test_dataloader = DataLoader(dataset=test_dataset,\n",
    "                             batch_size=BATCH_SIZE,\n",
    "                             shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050d0a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 1e-3\n",
    "\n",
    "EPOCHS = 200\n",
    "\n",
    "\n",
    "MODEL_SAVE_PATH = \"./ct_model_unet_\" + ANGLE +\".pth\"\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ffdac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = u_net(in_channels=1, feat=32).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fda9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "history = {'train_loss': [], 'val_loss': []}\n",
    "best_val_loss = None\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    tic = time.time()\n",
    "    model.train()\n",
    "    train_running_loss = 0\n",
    "    for idx, xydata in enumerate((train_dataloader)):\n",
    "        _xdata = xydata[0].float().to(device)\n",
    "        _ydata = xydata[1].float().to(device)\n",
    "\n",
    "        y_pred = model(_xdata)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        loss = criterion(y_pred, _ydata)\n",
    "        train_running_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    \n",
    "    scheduler.step()\n",
    "    \n",
    "    train_loss = train_running_loss / (idx + 1)\n",
    "\n",
    "    model.eval()\n",
    "    val_running_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for idx, xydata in enumerate(val_dataloader):\n",
    "            _xdata = xydata[0].float().to(device)\n",
    "            _ydata = xydata[1].float().to(device)\n",
    "\n",
    "            y_pred = model(_xdata)\n",
    "            loss = criterion(y_pred, _ydata)\n",
    "\n",
    "            val_running_loss += loss.item()\n",
    "        val_loss = val_running_loss / (idx + 1)\n",
    "\n",
    "    elapse = time.time() - tic\n",
    "    \n",
    "    history['train_loss'].append(train_loss)\n",
    "    history['val_loss'].append(val_loss)\n",
    "    \n",
    "    if best_val_loss is None or val_loss < best_val_loss:\n",
    "        torch.save(model.state_dict(), 'best-model-parameters-'+ANGLE+'.pt') # official recommended\n",
    "        best_val_loss = val_loss\n",
    "    \n",
    "    print(f\"Train Loss EPOCH {(epoch+1):6d}: {train_loss:6.4e} | Valid Loss EPOCH {(epoch+1):6d}: {val_loss:6.4e} | time: {elapse: 6.4f}\")\n",
    "\n",
    "torch.save(model.state_dict(), MODEL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc349868",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history['train_loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.yscale('log',base=10) \n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb8691dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load('./models/best-model-parameters-'+ANGLE+'.pt'), strict=True)\n",
    "model.eval()\n",
    "\n",
    "val_running_loss = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    for idx, xydata in enumerate(test_dataloader):\n",
    "        _xdata = xydata[0].float().to(device)\n",
    "        _ydata = xydata[1].float().to(device)\n",
    "\n",
    "        y_pred = model(_xdata)\n",
    "        loss = criterion(y_pred, _ydata)\n",
    "\n",
    "        val_running_loss += loss.item()\n",
    "        val_loss = val_running_loss / (idx + 1)\n",
    "\n",
    "    print(val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e81e0cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST MSE\n",
    "\n",
    "# 120 degrees :  0.0005778832914074883 (best)\n",
    "# 100 degress :  0.0009710367600200698 (best)\n",
    "# 80  degrees :  0.0013324491132516414 (best)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
