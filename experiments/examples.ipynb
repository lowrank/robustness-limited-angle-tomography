{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45080a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import scipy.io\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch.optim.lr_scheduler as lr_scheduler\n",
    "from tqdm import tqdm\n",
    "\n",
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv_op = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=\"same\"),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=\"same\"),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.BatchNorm2d(out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv_op(x)\n",
    "\n",
    "\n",
    "class DownSample(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "        self.pool = nn.AvgPool2d(kernel_size=(2,2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        down = self.conv(x)\n",
    "        p = self.pool(down)\n",
    "        return down, p\n",
    "\n",
    "\n",
    "class UpSample(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.up   = nn.UpsamplingNearest2d(scale_factor=2)\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        x = torch.cat([x1, x2], 1)\n",
    "        return self.conv(x)\n",
    "    \n",
    "    \n",
    "class u_net(nn.Module):\n",
    "    def __init__(self, in_channels, feat):\n",
    "        super().__init__()\n",
    "        self.down_convolution_1 = DownSample(in_channels,   feat)\n",
    "        self.down_convolution_2 = DownSample(    feat,  2 * feat)\n",
    "        self.down_convolution_3 = DownSample(2 * feat,  4 * feat)\n",
    "        self.down_convolution_4 = DownSample(4 * feat,  8 * feat)\n",
    "\n",
    "        self.bottle_neck        = DoubleConv(8 * feat, 16 * feat)\n",
    "\n",
    "        self.up_convolution_1 = UpSample(16 * feat + 8 * feat,  8 * feat)\n",
    "        self.up_convolution_2 = UpSample(8  * feat + 4 * feat,  4 * feat)\n",
    "        self.up_convolution_3 = UpSample(4  * feat + 2 * feat,  2 * feat)\n",
    "        self.up_convolution_4 = UpSample(2  * feat +     feat,      feat)\n",
    "\n",
    "        # Sigmoid to convert the numerics\n",
    "        self.out = nn.Conv2d(in_channels=feat, out_channels=1, kernel_size=1)\n",
    "        self.sig = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        down_1, p1 = self.down_convolution_1(x)\n",
    "        down_2, p2 = self.down_convolution_2(p1)\n",
    "        down_3, p3 = self.down_convolution_3(p2)\n",
    "        down_4, p4 = self.down_convolution_4(p3)\n",
    "\n",
    "        b = self.bottle_neck(p4)\n",
    "\n",
    "        up_1 = self.up_convolution_1(b, down_4)\n",
    "        up_2 = self.up_convolution_2(up_1, down_3)\n",
    "        up_3 = self.up_convolution_3(up_2, down_2)\n",
    "        up_4 = self.up_convolution_4(up_3, down_1)\n",
    "\n",
    "        out = self.out(up_4)\n",
    "       \n",
    "        return self.sig(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c1c6b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder containing .mat files\n",
    "\n",
    "ANGLE = \"80\" # visible angle \"120\", \"100\", \"80\"\n",
    "\n",
    "x_folder_path = 'train/XImages'+ANGLE\n",
    "y_folder_path = 'train/YImages'\n",
    "\n",
    "# List all .mat files in the folder\n",
    "x_mat_files = sorted([f for f in os.listdir(x_folder_path) if f.endswith('.mat')])\n",
    "y_mat_files = sorted([f for f in os.listdir(y_folder_path) if f.endswith('.mat')])\n",
    "\n",
    "x_train_list = []  # list of artifact images with missing angle (180 - ANGLE)\n",
    "y_train_list = []  # list of true images\n",
    "sample_size = 10000\n",
    "for i in range(sample_size):\n",
    "    x_mat = scipy.io.loadmat(os.path.join(x_folder_path, x_mat_files[i]))\n",
    "#     print(x_mat)\n",
    "    x_train = x_mat['P']\n",
    "    x_train_list.append(x_train)\n",
    "    \n",
    "    y_mat = scipy.io.loadmat(os.path.join(y_folder_path, y_mat_files[i]))\n",
    "    y_train = y_mat['im_reduced']\n",
    "    y_train_list.append(y_train)\n",
    "\n",
    "x_train_full = np.array(x_train_list)\n",
    "y_train_full = np.array(y_train_list)\n",
    "\n",
    "xdata = x_train_full[:5000]\n",
    "ydata = y_train_full[:5000]\n",
    "\n",
    "test_xdata = x_train_full[5000::]\n",
    "test_ydata = y_train_full[5000::]\n",
    "\n",
    "\n",
    "model80 = u_net(in_channels=1, feat=32).to(device)\n",
    "\n",
    "model80.load_state_dict(torch.load('./models/model_unet_'+ANGLE+'.pth'), strict=True)\n",
    "\n",
    "model80.eval()\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    _xdata80 = torch.tensor(test_xdata[1575]).unsqueeze(dim=0).unsqueeze(dim=0).float().to(device)\n",
    "    _ydata80 = torch.tensor(test_ydata[1575]).unsqueeze(dim=0).unsqueeze(dim=0).float().to(device)\n",
    "\n",
    "    y_pred80 = model80(_xdata80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f937d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to the folder containing .mat files\n",
    "\n",
    "ANGLE = \"100\" # visible angle \"120\", \"100\", \"80\"\n",
    "\n",
    "x_folder_path = 'train/XImages'+ANGLE\n",
    "y_folder_path = 'train/YImages'\n",
    "\n",
    "# List all .mat files in the folder\n",
    "x_mat_files = sorted([f for f in os.listdir(x_folder_path) if f.endswith('.mat')])\n",
    "y_mat_files = sorted([f for f in os.listdir(y_folder_path) if f.endswith('.mat')])\n",
    "\n",
    "x_train_list = []  # list of artifact images with missing angle (180 - ANGLE)\n",
    "y_train_list = []  # list of true images\n",
    "sample_size = 10000\n",
    "for i in range(sample_size):\n",
    "    x_mat = scipy.io.loadmat(os.path.join(x_folder_path, x_mat_files[i]))\n",
    "#     print(x_mat)\n",
    "    x_train = x_mat['P']\n",
    "    x_train_list.append(x_train)\n",
    "    \n",
    "    y_mat = scipy.io.loadmat(os.path.join(y_folder_path, y_mat_files[i]))\n",
    "    y_train = y_mat['im_reduced']\n",
    "    y_train_list.append(y_train)\n",
    "\n",
    "x_train_full = np.array(x_train_list)\n",
    "y_train_full = np.array(y_train_list)\n",
    "\n",
    "xdata = x_train_full[:5000]\n",
    "ydata = y_train_full[:5000]\n",
    "\n",
    "test_xdata = x_train_full[5000::]\n",
    "test_ydata = y_train_full[5000::]\n",
    "\n",
    "model100 = u_net(in_channels=1, feat=32).to(device)\n",
    "optimizer = optim.Adam(model80.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "criterion = nn.MSELoss()\n",
    "model100.load_state_dict(torch.load('./models/model_unet_'+ANGLE+'.pth'), strict=True)\n",
    "model100.eval()\n",
    "with torch.no_grad():\n",
    "    _xdata100 = torch.tensor(test_xdata[1576]).unsqueeze(dim=0).unsqueeze(dim=0).float().to(device)\n",
    "    _ydata100 = torch.tensor(test_ydata[1576]).unsqueeze(dim=0).unsqueeze(dim=0).float().to(device)\n",
    "\n",
    "    y_pred100 = model100(_xdata100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a97486",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ANGLE = \"120\" # visible angle \"120\", \"100\", \"80\"\n",
    "\n",
    "x_folder_path = 'train/XImages'+ANGLE\n",
    "y_folder_path = 'train/YImages'\n",
    "\n",
    "# List all .mat files in the folder\n",
    "x_mat_files = sorted([f for f in os.listdir(x_folder_path) if f.endswith('.mat')])\n",
    "y_mat_files = sorted([f for f in os.listdir(y_folder_path) if f.endswith('.mat')])\n",
    "\n",
    "x_train_list = []  # list of artifact images with missing angle (180 - ANGLE)\n",
    "y_train_list = []  # list of true images\n",
    "sample_size = 10000\n",
    "for i in range(sample_size):\n",
    "    x_mat = scipy.io.loadmat(os.path.join(x_folder_path, x_mat_files[i]))\n",
    "#     print(x_mat)\n",
    "    x_train = x_mat['P']\n",
    "    x_train_list.append(x_train)\n",
    "    \n",
    "    y_mat = scipy.io.loadmat(os.path.join(y_folder_path, y_mat_files[i]))\n",
    "    y_train = y_mat['im_reduced']\n",
    "    y_train_list.append(y_train)\n",
    "\n",
    "x_train_full = np.array(x_train_list)\n",
    "y_train_full = np.array(y_train_list)\n",
    "\n",
    "xdata = x_train_full[:5000]\n",
    "ydata = y_train_full[:5000]\n",
    "\n",
    "test_xdata = x_train_full[5000::]\n",
    "test_ydata = y_train_full[5000::]\n",
    "\n",
    "model120 = u_net(in_channels=1, feat=32).to(device)\n",
    "optimizer = optim.Adam(model120.parameters(), lr=LEARNING_RATE)\n",
    "scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.99)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "model120.load_state_dict(torch.load('./models/model_unet_'+ANGLE+'.pth'), strict=True)\n",
    "model120.eval()\n",
    "with torch.no_grad():\n",
    "\n",
    "    _xdata120 = torch.tensor(test_xdata[1577]).unsqueeze(dim=0).unsqueeze(dim=0).float().to(device)\n",
    "    _ydata120 = torch.tensor(test_ydata[1577]).unsqueeze(dim=0).unsqueeze(dim=0).float().to(device)\n",
    "\n",
    "    y_pred120 = model120(_xdata120)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d077a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(3, 3, 1)\n",
    "plt.imshow(_ydata80[0, 0].cpu(),cmap='gray')\n",
    "plt.axis('off')\n",
    "ax = fig.add_subplot(3, 3, 2)\n",
    "plt.imshow(_xdata80[0,0].cpu(),cmap='gray') \n",
    "plt.axis('off')\n",
    "ax = fig.add_subplot(3, 3, 3)\n",
    "plt.imshow(y_pred80[0, 0].cpu(),cmap='gray')\n",
    "plt.axis('off')\n",
    "ax = fig.add_subplot(3, 3, 4)\n",
    "plt.imshow(_ydata100[0, 0].cpu(),cmap='gray')\n",
    "plt.axis('off')\n",
    "ax = fig.add_subplot(3, 3, 5)\n",
    "plt.imshow(_xdata100[0,0].cpu(),cmap='gray') \n",
    "plt.axis('off')\n",
    "ax = fig.add_subplot(3, 3, 6)\n",
    "plt.imshow(y_pred100[0, 0].cpu(),cmap='gray')\n",
    "plt.axis('off')\n",
    "ax = fig.add_subplot(3, 3, 7)\n",
    "plt.imshow(_ydata120[0, 0].cpu(),cmap='gray')\n",
    "plt.axis('off')\n",
    "ax = fig.add_subplot(3, 3, 8)\n",
    "plt.imshow(_xdata120[0,0].cpu(),cmap='gray') \n",
    "plt.axis('off')\n",
    "ax = fig.add_subplot(3, 3, 9)\n",
    "plt.imshow(y_pred120[0, 0].cpu(),cmap='gray')\n",
    "plt.axis('off')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dc7771",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mat = scipy.io.loadmat(os.path.join('misc', 'sq_test_fbp80'))\n",
    "#     print(x_mat)\n",
    "x_train = x_mat['H']\n",
    "\n",
    "\n",
    "y_mat = scipy.io.loadmat(os.path.join('misc', 'sq_test_original'))\n",
    "y_train = y_mat['M']\n",
    "\n",
    "x_data = torch.tensor(x_train).unsqueeze(dim=0).unsqueeze(dim=0).float().to(device)\n",
    "y_data = torch.tensor(y_train).unsqueeze(dim=0).unsqueeze(dim=0).float().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    y_pred_data = model80(x_data)\n",
    "    \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 3, 1)\n",
    "plt.imshow(y_data[0,0].cpu(),cmap='gray')\n",
    "plt.axis('off')\n",
    "ax = fig.add_subplot(1, 3, 2)\n",
    "plt.imshow(x_data[0,0].cpu(),cmap='gray') \n",
    "plt.axis('off')\n",
    "ax = fig.add_subplot(1, 3, 3)\n",
    "plt.imshow(y_pred_data[0, 0].cpu(),cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5adad226",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mat = scipy.io.loadmat(os.path.join('misc', 'sq_test_fbp100'))\n",
    "#     print(x_mat)\n",
    "x_train = x_mat['H']\n",
    "\n",
    "\n",
    "y_mat = scipy.io.loadmat(os.path.join('misc', 'sq_test_original'))\n",
    "y_train = y_mat['M']\n",
    "\n",
    "x_data = torch.tensor(x_train).unsqueeze(dim=0).unsqueeze(dim=0).float().to(device)\n",
    "y_data = torch.tensor(y_train).unsqueeze(dim=0).unsqueeze(dim=0).float().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    y_pred_data = model100(x_data)\n",
    "    \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 3, 1)\n",
    "plt.imshow(y_data[0,0].cpu(),cmap='gray')\n",
    "plt.axis('off')\n",
    "ax = fig.add_subplot(1, 3, 2)\n",
    "plt.imshow(x_data[0,0].cpu(),cmap='gray') \n",
    "plt.axis('off')\n",
    "ax = fig.add_subplot(1, 3, 3)\n",
    "plt.imshow(y_pred_data[0, 0].cpu(),cmap='gray')\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821b38ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_mat = scipy.io.loadmat(os.path.join('misc', 'sq_test_fbp120'))\n",
    "#     print(x_mat)\n",
    "x_train = x_mat['H']\n",
    "\n",
    "\n",
    "y_mat = scipy.io.loadmat(os.path.join('misc', 'sq_test_original'))\n",
    "y_train = y_mat['M']\n",
    "\n",
    "x_data = torch.tensor(x_train).unsqueeze(dim=0).unsqueeze(dim=0).float().to(device)\n",
    "y_data = torch.tensor(y_train).unsqueeze(dim=0).unsqueeze(dim=0).float().to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    \n",
    "    y_pred_data = model120(x_data)\n",
    "    \n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1, 3, 1)\n",
    "plt.imshow(y_data[0,0].cpu(),cmap='gray')\n",
    "plt.axis('off')\n",
    "ax = fig.add_subplot(1, 3, 2)\n",
    "plt.imshow(x_data[0,0].cpu(),cmap='gray') \n",
    "plt.axis('off')\n",
    "ax = fig.add_subplot(1, 3, 3)\n",
    "plt.imshow(y_pred_data[0, 0].cpu(),cmap='gray')\n",
    "plt.axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
